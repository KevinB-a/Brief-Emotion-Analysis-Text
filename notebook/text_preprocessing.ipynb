{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd05b9c502b618e97131917a2f1409b4700bb639cdf99ce16cd88a0e27a90524386",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Importation des librairies dont on a besoin"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, '/home/apprenant/Documents/Brief-Emotion-Analysis-Text/')\n",
    "sys.path.append(Path(os.path.join(os.path.abspath(''), '../')).resolve().as_posix())\n",
    "import pandas as pd\n",
    "import spacy as sp\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from src.dataset import Dataset"
   ]
  },
  {
   "source": [
    "## Premier jeu de donn√©es"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/apprenant/Documents/Brief-Emotion-Analysis-Text/src/utils.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  texts = texts.str.replace(r\"(http|@)\\S+\", \"\")\n",
      "/home/apprenant/Documents/Brief-Emotion-Analysis-Text/src/utils.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  texts = texts.str.replace(r\"[^a-z\\':_]\", \" \")\n",
      "/home/apprenant/Documents/Brief-Emotion-Analysis-Text/src/utils.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  texts = texts.str.replace(r\"(can't|cannot)\", 'can not')\n",
      "Time to clean up: 9.84 sec\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path('/home/apprenant/Documents/Brief-Emotion-Analysis-Text/data/02_cleaned/cleaned_emotion_final.csv').resolve()\n",
    "dataset = Dataset(dataset_path)\n",
    "dataset.load()\n",
    "dataset.preprocess_texts()"
   ]
  },
  {
   "source": [
    "dataset.cleaned_data.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     label                                               text\n",
       "0  sadness                              didnt feel humiliated\n",
       "1  sadness  go feeling hopeless damned hopeful around some...\n",
       "2    anger          im grabbing minute post feel greedy wrong\n",
       "3     love  ever feeling nostalgic fireplace know still pr...\n",
       "4    anger                                    feeling grouchy"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sadness</td>\n      <td>didnt feel humiliated</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sadness</td>\n      <td>go feeling hopeless damned hopeful around some...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anger</td>\n      <td>im grabbing minute post feel greedy wrong</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>love</td>\n      <td>ever feeling nostalgic fireplace know still pr...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>anger</td>\n      <td>feeling grouchy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = dataset.cleaned_data"
   ]
  },
  {
   "source": [
    "### Tokenisation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset_list = cleaned_dataset['text'].to_list()\n",
    "\n",
    "tokenizer_w = WhitespaceTokenizer()\n",
    "token_list = []\n",
    "for i in cleaned_dataset_list:\n",
    "    tokenized_list = tokenizer_w.tokenize(i) \n",
    "    token_list.append(tokenized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_token_list = []\n",
    "for list in token_list:\n",
    "    for i in list:\n",
    "        new_token_list.append(i)"
   ]
  },
  {
   "source": [
    "### Stemming"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['didnt',\n",
       " 'feel',\n",
       " 'humili',\n",
       " 'go',\n",
       " 'feel',\n",
       " 'hopeless',\n",
       " 'damn',\n",
       " 'hope',\n",
       " 'around',\n",
       " 'someon',\n",
       " 'care',\n",
       " 'awak',\n",
       " 'im',\n",
       " 'grab',\n",
       " 'minut',\n",
       " 'post',\n",
       " 'feel',\n",
       " 'greedi',\n",
       " 'wrong',\n",
       " 'ever',\n",
       " 'feel',\n",
       " 'nostalg',\n",
       " 'fireplac',\n",
       " 'know',\n",
       " 'still',\n",
       " 'properti',\n",
       " 'feel',\n",
       " 'grouchi',\n",
       " 'ive',\n",
       " 'feel',\n",
       " 'littl',\n",
       " 'burden',\n",
       " 'late',\n",
       " 'wasnt',\n",
       " 'sure',\n",
       " 'ive',\n",
       " 'take',\n",
       " 'milligram',\n",
       " 'time',\n",
       " 'recommend',\n",
       " 'amount',\n",
       " 'ive',\n",
       " 'fallen',\n",
       " 'asleep',\n",
       " 'lot',\n",
       " 'faster',\n",
       " 'also',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'funni',\n",
       " 'feel',\n",
       " 'confus',\n",
       " 'life',\n",
       " 'teenag',\n",
       " 'jade',\n",
       " 'year',\n",
       " 'old',\n",
       " 'man',\n",
       " 'petrona',\n",
       " 'year',\n",
       " 'feel',\n",
       " 'petrona',\n",
       " 'perform',\n",
       " 'well',\n",
       " 'made',\n",
       " 'huge',\n",
       " 'profit',\n",
       " 'feel',\n",
       " 'romant',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'make',\n",
       " 'suffer',\n",
       " 'see',\n",
       " 'mean',\n",
       " 'someth',\n",
       " 'feel',\n",
       " 'run',\n",
       " 'divin',\n",
       " 'experi',\n",
       " 'expect',\n",
       " 'type',\n",
       " 'spiritu',\n",
       " 'encount',\n",
       " 'think',\n",
       " 'easiest',\n",
       " 'time',\n",
       " 'year',\n",
       " 'feel',\n",
       " 'dissatisfi',\n",
       " 'feel',\n",
       " 'low',\n",
       " 'energi',\n",
       " 'thirsti',\n",
       " 'immens',\n",
       " 'sympathi',\n",
       " 'general',\n",
       " 'point',\n",
       " 'possibl',\n",
       " 'proto',\n",
       " 'writer',\n",
       " 'tri',\n",
       " 'find',\n",
       " 'time',\n",
       " 'write',\n",
       " 'corner',\n",
       " 'life',\n",
       " 'no',\n",
       " 'sign',\n",
       " 'agent',\n",
       " 'let',\n",
       " 'alon',\n",
       " 'publish',\n",
       " 'contract',\n",
       " 'feel',\n",
       " 'littl',\n",
       " 'precious',\n",
       " 'not',\n",
       " 'feel',\n",
       " 'reassur',\n",
       " 'anxieti',\n",
       " 'side',\n",
       " 'didnt',\n",
       " 'realli',\n",
       " 'feel',\n",
       " 'embarrass',\n",
       " 'feel',\n",
       " 'pretti',\n",
       " 'pathet',\n",
       " 'time',\n",
       " 'start',\n",
       " 'feel',\n",
       " 'sentiment',\n",
       " 'doll',\n",
       " 'child',\n",
       " 'began',\n",
       " 'collect',\n",
       " 'vintag',\n",
       " 'barbi',\n",
       " 'doll',\n",
       " 'sixti',\n",
       " 'feel',\n",
       " 'compromis',\n",
       " 'skeptic',\n",
       " 'valu',\n",
       " 'everi',\n",
       " 'unit',\n",
       " 'work',\n",
       " 'put',\n",
       " 'feel',\n",
       " 'irrit',\n",
       " 'reject',\n",
       " 'without',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'say',\n",
       " 'anyth',\n",
       " 'feel',\n",
       " 'complet',\n",
       " 'overwhelm',\n",
       " 'two',\n",
       " 'strategi',\n",
       " 'help',\n",
       " 'feel',\n",
       " 'ground',\n",
       " 'pour',\n",
       " 'heart',\n",
       " 'journal',\n",
       " 'form',\n",
       " 'letter',\n",
       " 'god',\n",
       " 'end',\n",
       " 'list',\n",
       " 'five',\n",
       " 'thing',\n",
       " 'grate',\n",
       " 'feel',\n",
       " 'amus',\n",
       " 'delight',\n",
       " 'abl',\n",
       " 'help',\n",
       " 'chai',\n",
       " 'lifelin',\n",
       " 'support',\n",
       " 'encourag',\n",
       " 'great',\n",
       " 'feel',\n",
       " 'glad',\n",
       " 'abl',\n",
       " 'help',\n",
       " 'alreadi',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'fuck',\n",
       " 'though',\n",
       " 'dont',\n",
       " 'usual',\n",
       " 'eat',\n",
       " 'morn',\n",
       " 'still',\n",
       " 'love',\n",
       " 'wish',\n",
       " 'best',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'toler',\n",
       " 'effect',\n",
       " 'bm',\n",
       " 'live',\n",
       " 'fact',\n",
       " 'turn',\n",
       " 'bitter',\n",
       " 'angri',\n",
       " 'person',\n",
       " 'not',\n",
       " 'alway',\n",
       " 'particular',\n",
       " 'kind',\n",
       " 'peopl',\n",
       " 'around',\n",
       " 'feel',\n",
       " 'stress',\n",
       " 'feel',\n",
       " 'inhibit',\n",
       " 'someon',\n",
       " 'els',\n",
       " 'kitchen',\n",
       " 'like',\n",
       " 'im',\n",
       " 'paint',\n",
       " 'someon',\n",
       " 'els',\n",
       " 'pictur',\n",
       " 'becom',\n",
       " 'overwhelm',\n",
       " 'feel',\n",
       " 'defeat',\n",
       " 'feel',\n",
       " 'kinda',\n",
       " 'appal',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'need',\n",
       " 'explain',\n",
       " 'wide',\n",
       " 'lenghth',\n",
       " 'bodi',\n",
       " 'measur',\n",
       " 'etc',\n",
       " 'pp',\n",
       " 'feel',\n",
       " 'superior',\n",
       " 'dead',\n",
       " 'chicken',\n",
       " 'griev',\n",
       " 'child',\n",
       " 'get',\n",
       " 'giddi',\n",
       " 'feel',\n",
       " 'eleg',\n",
       " 'perfect',\n",
       " 'fit',\n",
       " 'pencil',\n",
       " 'skirt',\n",
       " 'rememb',\n",
       " 'feel',\n",
       " 'acut',\n",
       " 'distress',\n",
       " 'day',\n",
       " 'seen',\n",
       " 'heard',\n",
       " 'read',\n",
       " 'past',\n",
       " 'coupl',\n",
       " 'day',\n",
       " 'left',\n",
       " 'feel',\n",
       " 'impress',\n",
       " 'compani',\n",
       " 'climb',\n",
       " 'hill',\n",
       " 'feel',\n",
       " 'frustrat',\n",
       " 'id',\n",
       " 'pretti',\n",
       " 'much',\n",
       " 'pace',\n",
       " 'entir',\n",
       " 'wrong',\n",
       " 'cours',\n",
       " 'factor',\n",
       " 'never',\n",
       " 'ever',\n",
       " 'hamper',\n",
       " 'made',\n",
       " 'dent',\n",
       " 'day',\n",
       " 'imagin',\n",
       " 'real',\n",
       " 'life',\n",
       " 'scenario',\n",
       " 'would',\n",
       " 'emot',\n",
       " 'connect',\n",
       " 'enough',\n",
       " 'someon',\n",
       " 'feel',\n",
       " 'total',\n",
       " 'accept',\n",
       " 'safe',\n",
       " 'moral',\n",
       " 'accept',\n",
       " 'close',\n",
       " 'prolong',\n",
       " 'physic',\n",
       " 'contact',\n",
       " 'sex',\n",
       " 'expect',\n",
       " 'subsequ',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'would',\n",
       " 'make',\n",
       " 'feel',\n",
       " 'content',\n",
       " 'anyth',\n",
       " 'feel',\n",
       " 'need',\n",
       " 'creativ',\n",
       " 'howev',\n",
       " 'want',\n",
       " 'know',\n",
       " 'someth',\n",
       " 'someon',\n",
       " 'caus',\n",
       " 'feel',\n",
       " 'less',\n",
       " 'splendid',\n",
       " 'self',\n",
       " 'step',\n",
       " 'away',\n",
       " 'feel',\n",
       " 'bit',\n",
       " 'rude',\n",
       " 'write',\n",
       " 'elder',\n",
       " 'gentleman',\n",
       " 'ask',\n",
       " 'gift',\n",
       " 'feel',\n",
       " 'bit',\n",
       " 'greedi',\n",
       " 'christma',\n",
       " 'not',\n",
       " 'mild',\n",
       " 'greed',\n",
       " 'need',\n",
       " 'need',\n",
       " 'someon',\n",
       " 'need',\n",
       " 'protect',\n",
       " 'feel',\n",
       " 'safe',\n",
       " 'small',\n",
       " 'find',\n",
       " 'season',\n",
       " 'no',\n",
       " 'word',\n",
       " 'plan',\n",
       " 'share',\n",
       " 'everyday',\n",
       " 'life',\n",
       " 'stori',\n",
       " 'travel',\n",
       " 'adventur',\n",
       " 'inspir',\n",
       " 'handmad',\n",
       " 'creation',\n",
       " 'hope',\n",
       " 'also',\n",
       " 'feel',\n",
       " 'inspir',\n",
       " 'alreadi',\n",
       " 'christma',\n",
       " 'tree',\n",
       " 'got',\n",
       " 'two',\n",
       " 'feel',\n",
       " 'festiv',\n",
       " 'sure',\n",
       " 'spur',\n",
       " 'get',\n",
       " 'start',\n",
       " 'book',\n",
       " 'ive',\n",
       " 'worn',\n",
       " 'littl',\n",
       " 'conceal',\n",
       " 'day',\n",
       " 'im',\n",
       " 'feel',\n",
       " 'brave',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'pale',\n",
       " 'perfect',\n",
       " 'feel',\n",
       " 'strong',\n",
       " 'passion',\n",
       " 'jerk',\n",
       " 'decid',\n",
       " 'poke',\n",
       " 'make',\n",
       " 'fun',\n",
       " 'us',\n",
       " 'feel',\n",
       " 'discourag',\n",
       " 'alreadi',\n",
       " 'rob',\n",
       " 'peter',\n",
       " 'pay',\n",
       " 'paul',\n",
       " 'get',\n",
       " 'cow',\n",
       " 'year',\n",
       " 'cant',\n",
       " 'afford',\n",
       " 'not',\n",
       " 'get',\n",
       " 'cow',\n",
       " 'way',\n",
       " 'feel',\n",
       " 'listless',\n",
       " 'need',\n",
       " 'new',\n",
       " 'thing',\n",
       " 'someth',\n",
       " 'differ',\n",
       " 'lost',\n",
       " 'special',\n",
       " 'mind',\n",
       " 'worri',\n",
       " 'still',\n",
       " 'sane',\n",
       " 'want',\n",
       " 'feel',\n",
       " 'felt',\n",
       " 'read',\n",
       " 'book',\n",
       " 'know',\n",
       " 'mani',\n",
       " 'time',\n",
       " 'said',\n",
       " 'sam',\n",
       " 'special',\n",
       " 'guarante',\n",
       " 'mani',\n",
       " 'time',\n",
       " 'use',\n",
       " 'paragraph',\n",
       " 'tell',\n",
       " 'special',\n",
       " 'let',\n",
       " 'go',\n",
       " 'sad',\n",
       " 'feel',\n",
       " 'want',\n",
       " 'accept',\n",
       " 'first',\n",
       " 'home',\n",
       " 'mine',\n",
       " 'boat',\n",
       " 'trip',\n",
       " 'denmark',\n",
       " 'stop',\n",
       " 'feel',\n",
       " 'cold',\n",
       " 'began',\n",
       " 'feel',\n",
       " 'hot',\n",
       " 'need',\n",
       " 'feel',\n",
       " 'dough',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'perfect',\n",
       " 'found',\n",
       " 'feel',\n",
       " 'littl',\n",
       " 'discourag',\n",
       " 'morn',\n",
       " 'feel',\n",
       " 'selfish',\n",
       " 'spoil',\n",
       " 'stymi',\n",
       " 'littl',\n",
       " 'bit',\n",
       " 'wrote',\n",
       " 'feel',\n",
       " 'unsur',\n",
       " 'might',\n",
       " 'go',\n",
       " 'somewher',\n",
       " 'stori',\n",
       " 'unintend',\n",
       " 'bag',\n",
       " 'qaf',\n",
       " 'look',\n",
       " 'cryin',\n",
       " 'jacynth',\n",
       " 'lookin',\n",
       " 'good',\n",
       " 'feelin',\n",
       " 'gorgeous',\n",
       " 'rupaul',\n",
       " 'skin',\n",
       " 'scissor',\n",
       " 'sister',\n",
       " 'valentin',\n",
       " 'sun',\n",
       " 'fed',\n",
       " 'kayl',\n",
       " 'daddi',\n",
       " 'gerl',\n",
       " 'awak',\n",
       " 'unkind',\n",
       " 'u',\n",
       " 'feel',\n",
       " 'know',\n",
       " 'basic',\n",
       " 'like',\n",
       " 'fake',\n",
       " 'realm',\n",
       " 'scienc',\n",
       " 'fiction',\n",
       " 'hate',\n",
       " 'live',\n",
       " 'dad',\n",
       " 'roof',\n",
       " 'give',\n",
       " 'excus',\n",
       " 'asshol',\n",
       " 'hes',\n",
       " 'provid',\n",
       " 'live',\n",
       " 'think',\n",
       " 'feel',\n",
       " 'need',\n",
       " 'make',\n",
       " 'feel',\n",
       " 'unwelcom',\n",
       " 'possibl',\n",
       " 'ill',\n",
       " 'leav',\n",
       " 'keep',\n",
       " 'feel',\n",
       " 'pleasant',\n",
       " 'surpris',\n",
       " 'support',\n",
       " 'also',\n",
       " 'eas',\n",
       " 'new',\n",
       " 'situat',\n",
       " 'feel',\n",
       " 'anymor',\n",
       " 'vigor',\n",
       " 'sexual',\n",
       " 'activ',\n",
       " 'come',\n",
       " 'yes',\n",
       " 'misspelt',\n",
       " 'cum',\n",
       " 'day',\n",
       " 'part',\n",
       " 'begin',\n",
       " 'fall',\n",
       " 'feel',\n",
       " 'mom',\n",
       " 'grace',\n",
       " 'warm',\n",
       " 'love',\n",
       " 'smile',\n",
       " 'rob',\n",
       " 'time',\n",
       " 'nurtur',\n",
       " 'heal',\n",
       " 'feel',\n",
       " 'talk',\n",
       " 'brother',\n",
       " 'law',\n",
       " 'extrem',\n",
       " 'popular',\n",
       " 'one',\n",
       " 'no',\n",
       " 'think',\n",
       " 'stiff',\n",
       " 'ate',\n",
       " 'could',\n",
       " 'feel',\n",
       " 'gentl',\n",
       " 'tingl',\n",
       " 'throughout',\n",
       " 'almost',\n",
       " 'feel',\n",
       " 'heal',\n",
       " 'take',\n",
       " 'place',\n",
       " 'cellular',\n",
       " 'level',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'pressur',\n",
       " 'young',\n",
       " 'beauti',\n",
       " 'thin',\n",
       " 'depend',\n",
       " 'trend',\n",
       " 'girl',\n",
       " 'rejuven',\n",
       " 'butt',\n",
       " 'implant',\n",
       " 'began',\n",
       " 'sever',\n",
       " 'time',\n",
       " 'week',\n",
       " 'feel',\n",
       " 'tortur',\n",
       " 'hallucin',\n",
       " 'move',\n",
       " 'peopl',\n",
       " 'figur',\n",
       " 'sound',\n",
       " 'vibrat',\n",
       " 'near',\n",
       " 'finish',\n",
       " 'week',\n",
       " 'detox',\n",
       " 'feel',\n",
       " 'amaz',\n",
       " 'feel',\n",
       " 'selfish',\n",
       " 'read',\n",
       " 'back',\n",
       " 'former',\n",
       " 'post',\n",
       " 'never',\n",
       " 'ask',\n",
       " 'prayer',\n",
       " 'other',\n",
       " 'never',\n",
       " 'consid',\n",
       " 'may',\n",
       " 'other',\n",
       " 'deserv',\n",
       " 'prayer',\n",
       " 'answer',\n",
       " 'know',\n",
       " 'pain',\n",
       " 'parent',\n",
       " 'feel',\n",
       " 'enrag',\n",
       " 'child',\n",
       " 'becom',\n",
       " 'violent',\n",
       " 'roller',\n",
       " 'coaster',\n",
       " 'emot',\n",
       " 'suppos',\n",
       " 'feel',\n",
       " 'someth',\n",
       " 'unpleas',\n",
       " 'come',\n",
       " 'suppos',\n",
       " 'truth',\n",
       " 'need',\n",
       " 'share',\n",
       " 'havent',\n",
       " 'feel',\n",
       " 'faith',\n",
       " 'late',\n",
       " 'ive',\n",
       " 'dwell',\n",
       " 'doubt',\n",
       " 'uncertainti',\n",
       " 'faith',\n",
       " 'feel',\n",
       " 'brave',\n",
       " 'bought',\n",
       " 'clear',\n",
       " 'makeup',\n",
       " 'feel',\n",
       " 'miser',\n",
       " 'c',\n",
       " 'also',\n",
       " 'proudest',\n",
       " 'mum',\n",
       " 'earth',\n",
       " 'figur',\n",
       " 'famili',\n",
       " 'love',\n",
       " 'us',\n",
       " 'no',\n",
       " 'matter',\n",
       " 'around',\n",
       " 'anyon',\n",
       " 'els',\n",
       " 'feel',\n",
       " 'embarrass',\n",
       " 'michell',\n",
       " 'goe',\n",
       " 'ballist',\n",
       " 'necessarili',\n",
       " 'think',\n",
       " 'f',\n",
       " 'bomb',\n",
       " 'sex',\n",
       " 'necessari',\n",
       " 'stori',\n",
       " 'feel',\n",
       " 'reassur',\n",
       " 'see',\n",
       " 'print',\n",
       " 'journal',\n",
       " 'feel',\n",
       " 'ovari',\n",
       " 'ach',\n",
       " 'talk',\n",
       " 'like',\n",
       " 'put',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'much',\n",
       " 'chris',\n",
       " 'most',\n",
       " 'took',\n",
       " 'mani',\n",
       " 'pictur',\n",
       " 'unimport',\n",
       " 'stuff',\n",
       " 'im',\n",
       " 'tire',\n",
       " 'book',\n",
       " 'readi',\n",
       " 'find',\n",
       " 'given',\n",
       " 'unsuit',\n",
       " 'imag',\n",
       " 'feel',\n",
       " 'blame',\n",
       " 'result',\n",
       " 'not',\n",
       " 'sit',\n",
       " 'well',\n",
       " 'success',\n",
       " 'manag',\n",
       " 'stretch',\n",
       " 'mxm',\n",
       " 'canva',\n",
       " 'feel',\n",
       " 'achiev',\n",
       " 'worthwhil',\n",
       " 'usag',\n",
       " 'money',\n",
       " 'time',\n",
       " 'use',\n",
       " 'canva',\n",
       " 'futur',\n",
       " 'brief',\n",
       " 'think',\n",
       " 'feel',\n",
       " 'one',\n",
       " 'nay',\n",
       " 'import',\n",
       " 'thing',\n",
       " 'feel',\n",
       " 'complet',\n",
       " 'honor',\n",
       " 'influenc',\n",
       " 'young',\n",
       " 'talent',\n",
       " 'fulli',\n",
       " 'aliv',\n",
       " 'beauti',\n",
       " 'girl',\n",
       " 'woman',\n",
       " 'feel',\n",
       " 'anger',\n",
       " 'firey',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'miser',\n",
       " 'piec',\n",
       " 'garbag',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'need',\n",
       " 'make',\n",
       " 'list',\n",
       " 'leann',\n",
       " 'would',\n",
       " 'appal',\n",
       " 'thought',\n",
       " 'dont',\n",
       " 'miss',\n",
       " 'anyth',\n",
       " 'drove',\n",
       " 'dannika',\n",
       " 'school',\n",
       " 'feel',\n",
       " 'littl',\n",
       " 'bit',\n",
       " 'rush',\n",
       " 'greet',\n",
       " 'turn',\n",
       " 'corner',\n",
       " 'rememb',\n",
       " 'feel',\n",
       " 'hellip',\n",
       " 'furious',\n",
       " 'shooter',\n",
       " 'feel',\n",
       " 'happi',\n",
       " 'excit',\n",
       " 'sinc',\n",
       " 'learn',\n",
       " 'mani',\n",
       " 'thing',\n",
       " 'feel',\n",
       " 'show',\n",
       " 'around',\n",
       " 'show',\n",
       " 'hors',\n",
       " 'peopl',\n",
       " 'trust',\n",
       " 'relax',\n",
       " 'show',\n",
       " 'hors',\n",
       " 'safe',\n",
       " 'quiet',\n",
       " 'handl',\n",
       " 'frequent',\n",
       " 'coupl',\n",
       " 'thing',\n",
       " 'left',\n",
       " 'make',\n",
       " 'start',\n",
       " 'decemb',\n",
       " 'done',\n",
       " 'feel',\n",
       " 'smug',\n",
       " 'think',\n",
       " 'u',\n",
       " 'could',\n",
       " 'make',\n",
       " 'feel',\n",
       " 'realiz',\n",
       " 'everyth',\n",
       " 'ok',\n",
       " 'feel',\n",
       " 'worthless',\n",
       " 'time',\n",
       " 'struggl',\n",
       " 'find',\n",
       " 'work',\n",
       " 'abl',\n",
       " 'lay',\n",
       " 'bed',\n",
       " 'dark',\n",
       " 'not',\n",
       " 'feel',\n",
       " 'terrifi',\n",
       " 'least',\n",
       " 'readi',\n",
       " 'meet',\n",
       " 'mom',\n",
       " 'airport',\n",
       " 'feel',\n",
       " 'ever',\n",
       " 'support',\n",
       " 'arm',\n",
       " 'around',\n",
       " 'im',\n",
       " 'feel',\n",
       " 'bitter',\n",
       " 'today',\n",
       " 'mood',\n",
       " 'strang',\n",
       " 'entir',\n",
       " 'day',\n",
       " 'guess',\n",
       " 'mum',\n",
       " 'brother',\n",
       " 'pass',\n",
       " 'away',\n",
       " 'involv',\n",
       " 'car',\n",
       " 'accid',\n",
       " 'bring',\n",
       " 'present',\n",
       " 'pass',\n",
       " 'form',\n",
       " 'five',\n",
       " 'exam',\n",
       " 'fli',\n",
       " 'colour',\n",
       " 'let',\n",
       " 'go',\n",
       " 'animos',\n",
       " 'toward',\n",
       " 'anyon',\n",
       " 'feel',\n",
       " 'wrong',\n",
       " 'talk',\n",
       " 'dog',\n",
       " 'feel',\n",
       " 'not',\n",
       " 'understand',\n",
       " 'word',\n",
       " 'read',\n",
       " 'emot',\n",
       " 'know',\n",
       " 'support',\n",
       " 'decid',\n",
       " 'go',\n",
       " 'home',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'throw',\n",
       " 'away',\n",
       " 'shitti',\n",
       " 'piec',\n",
       " 'shit',\n",
       " 'paper',\n",
       " 'im',\n",
       " 'start',\n",
       " 'feel',\n",
       " 'wryli',\n",
       " 'amus',\n",
       " 'banal',\n",
       " 'comedi',\n",
       " 'error',\n",
       " 'life',\n",
       " 'turn',\n",
       " 'find',\n",
       " 'everi',\n",
       " 'bodi',\n",
       " 'beauti',\n",
       " 'want',\n",
       " 'peopl',\n",
       " 'feel',\n",
       " 'vital',\n",
       " 'bodi',\n",
       " 'hear',\n",
       " 'owner',\n",
       " 'feel',\n",
       " 'victim',\n",
       " 'associ',\n",
       " 'associ',\n",
       " 'attorney',\n",
       " 'properti',\n",
       " 'manag',\n",
       " 'say',\n",
       " 'goodby',\n",
       " 'fam',\n",
       " 'theyr',\n",
       " 'sad',\n",
       " 'cri',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'heartless',\n",
       " 'bitch',\n",
       " 'hey',\n",
       " 'im',\n",
       " 'pretti',\n",
       " 'excit',\n",
       " 'fli',\n",
       " 'first',\n",
       " 'time',\n",
       " 'know',\n",
       " 'also',\n",
       " 'spend',\n",
       " 'year',\n",
       " 'anoth',\n",
       " 'countri',\n",
       " 'wont',\n",
       " 'let',\n",
       " 'child',\n",
       " 'cri',\n",
       " 'feel',\n",
       " 'love',\n",
       " 'lili',\n",
       " 'littl',\n",
       " 'go',\n",
       " 'opportun',\n",
       " 'last',\n",
       " 'short',\n",
       " 'month',\n",
       " 'alba',\n",
       " 'feel',\n",
       " 'good',\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "def stemmer_snowball(text_list):\n",
    "    snowball = SnowballStemmer(language='english')\n",
    "    return_list = []\n",
    "    for i in range(len(text_list)):\n",
    "        return_list.append(snowball.stem(text_list[i]))\n",
    "    return(return_list)\n",
    "\n",
    "stemmer_snowball(new_token_list)"
   ]
  },
  {
   "source": [
    "### Vectorization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x)\n",
    "X = vectorizer.fit_transform(new_token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "source": [
    "### Enregistrement de la matrice du premier jeu de donn√©es"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=X)\n",
    "df.to_csv('/home/apprenant/Documents/Brief-Emotion-Analysis-Text/data/03_vectorized/emotion_final_matrix.csv', index=False)"
   ]
  },
  {
   "source": [
    "## Second jeu de donn√©es"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/apprenant/Documents/Brief-Emotion-Analysis-Text/src/utils.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  texts = texts.str.replace(r\"(http|@)\\S+\", \"\")\n",
      "/home/apprenant/Documents/Brief-Emotion-Analysis-Text/src/utils.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  texts = texts.str.replace(r\"[^a-z\\':_]\", \" \")\n",
      "/home/apprenant/Documents/Brief-Emotion-Analysis-Text/src/utils.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  texts = texts.str.replace(r\"(can't|cannot)\", 'can not')\n",
      "Time to clean up: 13.21 sec\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path('/home/apprenant/Documents/Brief-Emotion-Analysis-Text/data/02_cleaned/cleaned_text_emotion.csv').resolve()\n",
    "dataset = Dataset(dataset_path)\n",
    "dataset.load()\n",
    "dataset.preprocess_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        label                                               text\n",
       "0       empty  know listenin bad habit earlier started freaki...\n",
       "1     sadness               layin n bed headache ugh waitin call\n",
       "2     sadness                     funeral ceremony gloomy friday\n",
       "3  enthusiasm                            wants hang friends soon\n",
       "4     neutral          want trade someone houston tickets no one"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>empty</td>\n      <td>know listenin bad habit earlier started freaki...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sadness</td>\n      <td>layin n bed headache ugh waitin call</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sadness</td>\n      <td>funeral ceremony gloomy friday</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>enthusiasm</td>\n      <td>wants hang friends soon</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neutral</td>\n      <td>want trade someone houston tickets no one</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "dataset.cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = dataset.cleaned_data"
   ]
  },
  {
   "source": [
    "### Tokenisation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset_list = cleaned_dataset['text'].to_list()\n",
    "\n",
    "tokenizer_w = WhitespaceTokenizer()\n",
    "token_list = []\n",
    "for i in cleaned_dataset_list:\n",
    "    tokenized_list = tokenizer_w.tokenize(i) \n",
    "    token_list.append(tokenized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_token_list = []\n",
    "for list in token_list:\n",
    "    for i in list:\n",
    "        new_token_list.append(i)"
   ]
  },
  {
   "source": [
    "### Stemming"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['know',\n",
       " 'listenin',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'earlier',\n",
       " 'start',\n",
       " 'freakin',\n",
       " 'part',\n",
       " 'layin',\n",
       " 'n',\n",
       " 'bed',\n",
       " 'headach',\n",
       " 'ugh',\n",
       " 'waitin',\n",
       " 'call',\n",
       " 'funer',\n",
       " 'ceremoni',\n",
       " 'gloomi',\n",
       " 'friday',\n",
       " 'want',\n",
       " 'hang',\n",
       " 'friend',\n",
       " 'soon',\n",
       " 'want',\n",
       " 'trade',\n",
       " 'someon',\n",
       " 'houston',\n",
       " 'ticket',\n",
       " 'no',\n",
       " 'one',\n",
       " 'ping',\n",
       " 'not',\n",
       " 'go',\n",
       " 'prom',\n",
       " 'bc',\n",
       " 'bf',\n",
       " 'not',\n",
       " 'like',\n",
       " 'friend',\n",
       " 'sleep',\n",
       " 'im',\n",
       " 'not',\n",
       " 'think',\n",
       " 'old',\n",
       " 'friend',\n",
       " 'want',\n",
       " 'he',\n",
       " 'marri',\n",
       " 'damn',\n",
       " 'amp',\n",
       " 'want',\n",
       " 'scandal',\n",
       " 'hm',\n",
       " 'charlen',\n",
       " 'love',\n",
       " 'miss',\n",
       " \"i'm\",\n",
       " 'sorri',\n",
       " 'least',\n",
       " 'friday',\n",
       " 'cant',\n",
       " 'fall',\n",
       " 'asleep',\n",
       " 'choke',\n",
       " 'retain',\n",
       " 'ugh',\n",
       " 'beat',\n",
       " 'stupid',\n",
       " 'song',\n",
       " 'get',\n",
       " 'next',\n",
       " 'rude',\n",
       " 'u',\n",
       " 'watch',\n",
       " 'hill',\n",
       " 'london',\n",
       " 'u',\n",
       " 'realis',\n",
       " 'tourtur',\n",
       " 'week',\n",
       " 'week',\n",
       " 'late',\n",
       " 'watch',\n",
       " 'itonlinelol',\n",
       " 'got',\n",
       " 'news',\n",
       " 'storm',\n",
       " 'electr',\n",
       " 'gone',\n",
       " 'agre',\n",
       " 'sleepi',\n",
       " 'not',\n",
       " 'even',\n",
       " 'late',\n",
       " 'fail',\n",
       " 'ladi',\n",
       " 'gaga',\n",
       " 'tweet',\n",
       " 'not',\n",
       " 'impress',\n",
       " 'video',\n",
       " 'leak',\n",
       " 'know',\n",
       " 'convinc',\n",
       " 'alway',\n",
       " 'want',\n",
       " 'signal',\n",
       " 'give',\n",
       " 'damn',\n",
       " 'think',\n",
       " 'lost',\n",
       " 'anoth',\n",
       " 'friend',\n",
       " 'oh',\n",
       " 'bad',\n",
       " 'hope',\n",
       " 'get',\n",
       " 'better',\n",
       " \"i'v\",\n",
       " 'sleep',\n",
       " 'issu',\n",
       " 'late',\n",
       " 'wonder',\n",
       " \"i'm\",\n",
       " 'awak',\n",
       " 'write',\n",
       " 'new',\n",
       " 'song',\n",
       " 'plot',\n",
       " 'evil',\n",
       " 'secret',\n",
       " 'plot',\n",
       " 'muahahaha',\n",
       " 'oh',\n",
       " 'damn',\n",
       " 'not',\n",
       " 'secret',\n",
       " 'anymor',\n",
       " 'no',\n",
       " 'topic',\n",
       " 'map',\n",
       " 'talk',\n",
       " 'balisag',\n",
       " 'markup',\n",
       " 'confer',\n",
       " 'program',\n",
       " 'onlin',\n",
       " 'via',\n",
       " 'topicmap',\n",
       " 'ate',\n",
       " 'someth',\n",
       " 'not',\n",
       " 'know',\n",
       " 'keep',\n",
       " 'tell',\n",
       " 'thing',\n",
       " 'food',\n",
       " 'tire',\n",
       " 'think',\n",
       " \"i'm\",\n",
       " 'definit',\n",
       " 'go',\n",
       " 'get',\n",
       " 'ear',\n",
       " 'infect',\n",
       " 'go',\n",
       " 'bed',\n",
       " 'quot',\n",
       " 'earli',\n",
       " 'quot',\n",
       " 'way',\n",
       " 'home',\n",
       " 'n',\n",
       " 'deal',\n",
       " 'w',\n",
       " 'underag',\n",
       " 'girl',\n",
       " 'drink',\n",
       " 'gin',\n",
       " 'da',\n",
       " 'bus',\n",
       " 'talk',\n",
       " 'bout',\n",
       " 'kegger',\n",
       " 'damn',\n",
       " 'feel',\n",
       " 'old',\n",
       " \"i'm\",\n",
       " 'sorri',\n",
       " 'peopl',\n",
       " 'rude',\n",
       " 'isaac',\n",
       " 'get',\n",
       " 'manner',\n",
       " 'know',\n",
       " 'better',\n",
       " 'lewd',\n",
       " 'damm',\n",
       " 'server',\n",
       " 'still',\n",
       " 'need',\n",
       " 'hit',\n",
       " 'koxper',\n",
       " 'pass',\n",
       " 'fudg',\n",
       " \"bs'd\",\n",
       " 'whole',\n",
       " 'paper',\n",
       " 'tire',\n",
       " 'ugh',\n",
       " 'hate',\n",
       " 'school',\n",
       " 'time',\n",
       " 'sleep',\n",
       " 'hate',\n",
       " 'cancer',\n",
       " 'hate',\n",
       " 'hate',\n",
       " 'hate',\n",
       " 'annoy',\n",
       " 'start',\n",
       " 'type',\n",
       " 'comput',\n",
       " 'middl',\n",
       " 'night',\n",
       " 'cant',\n",
       " 'sleep',\n",
       " 'miss',\n",
       " 'bl',\n",
       " 'bus',\n",
       " 'feel',\n",
       " 'strong',\n",
       " 'contract',\n",
       " 'want',\n",
       " 'go',\n",
       " 'socal',\n",
       " 'stoke',\n",
       " 'mayb',\n",
       " 'not',\n",
       " 'tomorrow',\n",
       " 'screw',\n",
       " 'week',\n",
       " 'yeah',\n",
       " ':s',\n",
       " 'feel',\n",
       " 'funni',\n",
       " 'caus',\n",
       " 'not',\n",
       " 'slept',\n",
       " 'enough',\n",
       " 'woke',\n",
       " 'mum',\n",
       " 'caus',\n",
       " 'sing',\n",
       " 'not',\n",
       " 'impress',\n",
       " ':s',\n",
       " 'need',\n",
       " 'skott',\n",
       " 'right',\n",
       " 'work',\n",
       " 'afternoon',\n",
       " 'aw',\n",
       " 'would',\n",
       " 'not',\n",
       " 'unfollow',\n",
       " 'would',\n",
       " 'would',\n",
       " 'cri',\n",
       " 'much',\n",
       " 'better',\n",
       " 'day',\n",
       " 'far',\n",
       " 'still',\n",
       " 'quit',\n",
       " 'earli',\n",
       " 'last',\n",
       " 'day',\n",
       " 'ud',\n",
       " 'lt',\n",
       " 'gonna',\n",
       " 'first',\n",
       " 'twitter',\n",
       " 'caus',\n",
       " 'amaz',\n",
       " 'lol',\n",
       " 'come',\n",
       " 'canada',\n",
       " 'would',\n",
       " 'anyth',\n",
       " 'see',\n",
       " 'perform',\n",
       " 'pick',\n",
       " 'blackberri',\n",
       " 'middl',\n",
       " 'street',\n",
       " 'crush',\n",
       " 'feel',\n",
       " 'pack',\n",
       " 'hit',\n",
       " 'sfo',\n",
       " 'around',\n",
       " 'time',\n",
       " 'year',\n",
       " 'think',\n",
       " \"i'm\",\n",
       " 'miss',\n",
       " 'someth',\n",
       " 'middl',\n",
       " 'school',\n",
       " 'elem',\n",
       " 'high',\n",
       " 'school',\n",
       " 'remain',\n",
       " 'open',\n",
       " 'need',\n",
       " 'credit',\n",
       " 'graduat',\n",
       " 'cali',\n",
       " 'broken',\n",
       " 'bed',\n",
       " 'time',\n",
       " 'hope',\n",
       " 'go',\n",
       " 'school',\n",
       " 'tomorrow',\n",
       " 'though',\n",
       " 'not',\n",
       " 'feel',\n",
       " 'well',\n",
       " 'right',\n",
       " 'ahh',\n",
       " 'well',\n",
       " 'hope',\n",
       " 'could',\n",
       " 'learn',\n",
       " 'stuff',\n",
       " 'way',\n",
       " 'not',\n",
       " 'work',\n",
       " 'separ',\n",
       " 'thing',\n",
       " 'also',\n",
       " \"i'm\",\n",
       " 'problem',\n",
       " 'photo',\n",
       " 'twitter',\n",
       " 'amf',\n",
       " 'not',\n",
       " 'see',\n",
       " 'face',\n",
       " 'oh',\n",
       " 'no',\n",
       " 'blow',\n",
       " 'tire',\n",
       " 'realli',\n",
       " 'go',\n",
       " 'send',\n",
       " 'batman',\n",
       " 'smoke',\n",
       " 'wnna',\n",
       " 'take',\n",
       " 'bath',\n",
       " 'chocol',\n",
       " 'milk',\n",
       " 'much',\n",
       " 'better',\n",
       " 'straw',\n",
       " 'lack',\n",
       " 'said',\n",
       " 'straw',\n",
       " 'tire',\n",
       " 'hey',\n",
       " 'yu',\n",
       " 'lil',\n",
       " 'fucker',\n",
       " 'textd',\n",
       " 'yu',\n",
       " 'time',\n",
       " 'diff',\n",
       " \"i'v\",\n",
       " 'wrap',\n",
       " 'day',\n",
       " 'day',\n",
       " 'stuff',\n",
       " 'havent',\n",
       " 'tweet',\n",
       " 'talk',\n",
       " 'soon',\n",
       " 'must',\n",
       " 'sleep',\n",
       " 'hrs',\n",
       " 'no',\n",
       " 'way',\n",
       " 'damn',\n",
       " 'suck',\n",
       " 'b',\n",
       " 'ok',\n",
       " 'suck',\n",
       " 'not',\n",
       " 'abl',\n",
       " 'take',\n",
       " 'day',\n",
       " 'work',\n",
       " 'money',\n",
       " 'take',\n",
       " 'trip',\n",
       " 'sad',\n",
       " 'bed',\n",
       " 'sorta',\n",
       " 'today',\n",
       " 'good',\n",
       " 'sara',\n",
       " 'strep',\n",
       " 'thought',\n",
       " 'angelina',\n",
       " 'share',\n",
       " 'water',\n",
       " 'b',\n",
       " 'told',\n",
       " 'prob',\n",
       " 'get',\n",
       " 'recess',\n",
       " 'hotel',\n",
       " 'restructur',\n",
       " 'account',\n",
       " 'done',\n",
       " 'add',\n",
       " 'bit',\n",
       " 'pressur',\n",
       " 'short',\n",
       " 'term',\n",
       " \"we'll\",\n",
       " 'cope',\n",
       " 'got',\n",
       " 'dib',\n",
       " 'sulu',\n",
       " 'aww',\n",
       " 'onward',\n",
       " 'upward',\n",
       " 'yay',\n",
       " 'still',\n",
       " 'sad',\n",
       " 'leav',\n",
       " 'bet',\n",
       " 'haha',\n",
       " 'poor',\n",
       " 'abi',\n",
       " 'still',\n",
       " 'get',\n",
       " 'sore',\n",
       " 'diesel',\n",
       " 'yari',\n",
       " 'mpg',\n",
       " 'sad',\n",
       " 'not',\n",
       " 'avail',\n",
       " 'us',\n",
       " \"that'd\",\n",
       " 'awesom',\n",
       " 'want',\n",
       " 'buy',\n",
       " 'great',\n",
       " 'album',\n",
       " 'unfortun',\n",
       " 'dont',\n",
       " 'hav',\n",
       " 'enuff',\n",
       " 'fund',\n",
       " 'quot',\n",
       " 'long',\n",
       " 'time',\n",
       " 'noisi',\n",
       " 'quot',\n",
       " 'honesti',\n",
       " 'pain',\n",
       " 'blech',\n",
       " 'ok',\n",
       " 'passeng',\n",
       " 'no',\n",
       " 'one',\n",
       " 'aliv',\n",
       " \"they'r\",\n",
       " 'dead',\n",
       " 'not',\n",
       " 'know',\n",
       " 'til',\n",
       " 'end',\n",
       " 'cri',\n",
       " 'home',\n",
       " 'alon',\n",
       " 'not',\n",
       " 'much',\n",
       " 'ia',\n",
       " 'much',\n",
       " 'not',\n",
       " 'realli',\n",
       " 'happi',\n",
       " 'cook',\n",
       " 'choic',\n",
       " 'singl',\n",
       " 'fell',\n",
       " 'asleep',\n",
       " 'beach',\n",
       " 'not',\n",
       " 'put',\n",
       " 'enough',\n",
       " 'sunscreen',\n",
       " 'lol',\n",
       " 'think',\n",
       " 'son',\n",
       " 'might',\n",
       " 'flu',\n",
       " 'caus',\n",
       " 'def',\n",
       " 'clean',\n",
       " 'stanki',\n",
       " 'puke',\n",
       " 'mess',\n",
       " 'poor',\n",
       " 'pumkpin',\n",
       " 'great',\n",
       " 'see',\n",
       " 'oin',\n",
       " 'amp',\n",
       " 'cynthia',\n",
       " 'happi',\n",
       " 'dinner',\n",
       " 'great',\n",
       " 'cute',\n",
       " 'littl',\n",
       " 'place',\n",
       " 'bad',\n",
       " 'oin',\n",
       " 'got',\n",
       " 'sick',\n",
       " 'afterward',\n",
       " 'cant',\n",
       " 'give',\n",
       " 'bday',\n",
       " 'nudg',\n",
       " 'woman',\n",
       " 'transfer',\n",
       " 'first',\n",
       " 'impress',\n",
       " 'sexual',\n",
       " 'matern',\n",
       " 'onto',\n",
       " 'less',\n",
       " 'threaten',\n",
       " 'man',\n",
       " 'weak',\n",
       " 'him',\n",
       " 'brother',\n",
       " 'bloom',\n",
       " 'wo',\n",
       " 'not',\n",
       " 'open',\n",
       " 'weekend',\n",
       " 'el',\n",
       " 'paso',\n",
       " \"i'll\",\n",
       " 'buy',\n",
       " 'brick',\n",
       " 'enjoy',\n",
       " 'watch',\n",
       " 'brother',\n",
       " 'bloom',\n",
       " 'say',\n",
       " 'miss',\n",
       " 'plurk',\n",
       " 'bitten',\n",
       " 'blood',\n",
       " 'cat',\n",
       " 'way',\n",
       " 'rabi',\n",
       " 'bacterin',\n",
       " 'seem',\n",
       " 'shot',\n",
       " 'month',\n",
       " 'never',\n",
       " 'wash',\n",
       " 'cat',\n",
       " 'home',\n",
       " 'hate',\n",
       " 'water',\n",
       " 'miss',\n",
       " 'voobi',\n",
       " 'neither',\n",
       " 'elp',\n",
       " 'dude',\n",
       " 'favorit',\n",
       " 'sandwich',\n",
       " 'place',\n",
       " 'ever',\n",
       " 'um',\n",
       " 'take',\n",
       " 'pictur',\n",
       " 'sad',\n",
       " 'shin',\n",
       " 'ae',\n",
       " 'got',\n",
       " 'marri',\n",
       " 'not',\n",
       " 'alex',\n",
       " 'sure',\n",
       " 'tweet',\n",
       " 'back',\n",
       " 'news',\n",
       " 'abuzz',\n",
       " 'tr',\n",
       " 'knight',\n",
       " 'leav',\n",
       " 'quot',\n",
       " 'confirm',\n",
       " 'quot',\n",
       " 'today',\n",
       " 'muy',\n",
       " 'trist',\n",
       " 'ohh',\n",
       " 'thursday',\n",
       " 'exam',\n",
       " 'day',\n",
       " 'wednesday',\n",
       " 'mix',\n",
       " 'dentist',\n",
       " 'appt',\n",
       " 'afternoon',\n",
       " 'reschedul',\n",
       " 'tomorrow',\n",
       " 'think',\n",
       " 'excit',\n",
       " 'guy',\n",
       " 'move',\n",
       " 'realiz',\n",
       " 'sad',\n",
       " 'see',\n",
       " 'go',\n",
       " 'god',\n",
       " 'morn',\n",
       " 'peopl',\n",
       " 'sun',\n",
       " 'definit',\n",
       " 'spring',\n",
       " 'first',\n",
       " 'spring',\n",
       " 'hail',\n",
       " 'storm',\n",
       " 'car',\n",
       " 'dimpl',\n",
       " 'love',\n",
       " \"it'sakey\",\n",
       " 'usb',\n",
       " 'stick',\n",
       " 'gb',\n",
       " 'australia',\n",
       " 'fresh',\n",
       " 'princ',\n",
       " 'sleepi',\n",
       " 'sleep',\n",
       " 'night',\n",
       " 'routin',\n",
       " 'gotta',\n",
       " 'go',\n",
       " 'dmv',\n",
       " 'earli',\n",
       " 'tmrw',\n",
       " 'dammit',\n",
       " 'hulu',\n",
       " 'desktop',\n",
       " 'total',\n",
       " 'screw',\n",
       " 'abil',\n",
       " 'talk',\n",
       " 'particular',\n",
       " 'port',\n",
       " 'one',\n",
       " 'dev',\n",
       " 'server',\n",
       " 'not',\n",
       " 'watch',\n",
       " 'code',\n",
       " 'jealous',\n",
       " 'mom',\n",
       " 'talk',\n",
       " 'want',\n",
       " 'see',\n",
       " 'twitter',\n",
       " 'make',\n",
       " 'miss',\n",
       " 'not',\n",
       " 'sleep',\n",
       " 'keep',\n",
       " 'think',\n",
       " 'puppi',\n",
       " 'play',\n",
       " 'today',\n",
       " \"i'm\",\n",
       " 'supos',\n",
       " 'sleep',\n",
       " 'got',\n",
       " 'much',\n",
       " 'amp',\n",
       " 'got',\n",
       " 'one',\n",
       " 'part',\n",
       " 'song',\n",
       " 'stuck',\n",
       " 'head',\n",
       " 'quot',\n",
       " 'jerk',\n",
       " 'iknow',\n",
       " 'quot',\n",
       " 'blaahh',\n",
       " 'what',\n",
       " 'go',\n",
       " 'sweetheart',\n",
       " 'freak',\n",
       " 'difficult',\n",
       " 'get',\n",
       " 'system',\n",
       " 'wide',\n",
       " 'spellcheck',\n",
       " 'shit',\n",
       " \"i'd\",\n",
       " 'settl',\n",
       " 'offic',\n",
       " 'suit',\n",
       " 'one',\n",
       " 'stupid',\n",
       " 'unhelp',\n",
       " 'window',\n",
       " 'last',\n",
       " 'one',\n",
       " 'month',\n",
       " 'due',\n",
       " 'summer',\n",
       " 'strawberri',\n",
       " 'not',\n",
       " 'availbl',\n",
       " 'chennai',\n",
       " 'market',\n",
       " 'work',\n",
       " 'gotta',\n",
       " 'go',\n",
       " 'bed',\n",
       " 'soon',\n",
       " 'correct',\n",
       " 'ador',\n",
       " 'pluck',\n",
       " 'put',\n",
       " 'arm',\n",
       " 'cuz',\n",
       " 'cryin',\n",
       " 'better',\n",
       " 'hahaha',\n",
       " 'hi',\n",
       " 'im',\n",
       " 'ipod',\n",
       " 'cant',\n",
       " 'fall',\n",
       " 'asleep',\n",
       " 'dont',\n",
       " 'wanna',\n",
       " 'work',\n",
       " 'tomorrow',\n",
       " 'get',\n",
       " 'paid',\n",
       " 'feel',\n",
       " 'sad',\n",
       " 'coz',\n",
       " 'wasnt',\n",
       " 'abl',\n",
       " 'play',\n",
       " 'guy',\n",
       " 'princecharm',\n",
       " 'cayogi',\n",
       " 'want',\n",
       " 'come',\n",
       " 'bz',\n",
       " 'summer',\n",
       " ':',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'anymor',\n",
       " 'teacher',\n",
       " 'life',\n",
       " 'summer',\n",
       " 'suck',\n",
       " 'first',\n",
       " 'ever',\n",
       " 'drop',\n",
       " 'call',\n",
       " 'mobil',\n",
       " 'call',\n",
       " 'no',\n",
       " 'less',\n",
       " 'charg',\n",
       " 'data',\n",
       " 'even',\n",
       " 'though',\n",
       " 'data',\n",
       " 'pack',\n",
       " 'win',\n",
       " 'sigh',\n",
       " 'rakeem',\n",
       " 'oh',\n",
       " 'time',\n",
       " 'real',\n",
       " 'darn',\n",
       " 'allergi',\n",
       " 'not',\n",
       " 'like',\n",
       " 'time',\n",
       " 'year',\n",
       " 'never',\n",
       " 'use',\n",
       " 'problem',\n",
       " 'either',\n",
       " 'oh',\n",
       " 'no',\n",
       " 'one',\n",
       " 'minut',\n",
       " 'late',\n",
       " 'oh',\n",
       " 'well',\n",
       " 'damn',\n",
       " 'suck',\n",
       " 'want',\n",
       " 'come',\n",
       " 'bz',\n",
       " 'summer',\n",
       " ':',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'anymor',\n",
       " 'teacher',\n",
       " 'life',\n",
       " 'summer',\n",
       " 'suck',\n",
       " 'websit',\n",
       " 'gave',\n",
       " 'virus',\n",
       " 'open',\n",
       " 'window',\n",
       " 'kept',\n",
       " 'pop',\n",
       " 'ahh',\n",
       " 'big',\n",
       " 'scari',\n",
       " 'bug',\n",
       " 'fli',\n",
       " 'around',\n",
       " 'room',\n",
       " 'wish',\n",
       " 'knew',\n",
       " 'put',\n",
       " 'stole',\n",
       " 'heart',\n",
       " 'never',\n",
       " 'gave',\n",
       " 'back',\n",
       " 'occasion',\n",
       " 'like',\n",
       " 'like',\n",
       " 'look',\n",
       " 'nasti',\n",
       " 'cough',\n",
       " 'cant',\n",
       " 'sick',\n",
       " 'huge',\n",
       " 'weekend',\n",
       " 'ahead',\n",
       " 'stone',\n",
       " 'cold',\n",
       " 'crazi',\n",
       " \"i'm\",\n",
       " 'tire',\n",
       " 'shift',\n",
       " 'time',\n",
       " 'bbye',\n",
       " 'biochem',\n",
       " 'wah',\n",
       " \"i'm\",\n",
       " 'sure',\n",
       " 'cum',\n",
       " 'play',\n",
       " \"i'm\",\n",
       " 'workin',\n",
       " 'til',\n",
       " 'midnight',\n",
       " 'second',\n",
       " 'wish',\n",
       " 'rain',\n",
       " 'earli',\n",
       " 'happi',\n",
       " 'day',\n",
       " 'birth',\n",
       " 'case',\n",
       " 'not',\n",
       " 'make',\n",
       " 'tire',\n",
       " 'therapi',\n",
       " 'today',\n",
       " 'n',\n",
       " 'take',\n",
       " 'medicin',\n",
       " 'misshu',\n",
       " 'love',\n",
       " 'ya',\n",
       " 'damn',\n",
       " 'eric',\n",
       " 'anyon',\n",
       " 'els',\n",
       " 'need',\n",
       " 'hair',\n",
       " 'play',\n",
       " \"i'm\",\n",
       " 'feel',\n",
       " 'deflat',\n",
       " 'ugh',\n",
       " 'no',\n",
       " 'dog',\n",
       " 'allergi',\n",
       " 'suck',\n",
       " 'duck',\n",
       " 'nut',\n",
       " 'lt',\n",
       " 'well',\n",
       " 'almost',\n",
       " 'good',\n",
       " 'day',\n",
       " 'guess',\n",
       " 'retri',\n",
       " 'tomorrow',\n",
       " 'waraku',\n",
       " 'tasteless',\n",
       " 'expens',\n",
       " 'portion',\n",
       " 'littl',\n",
       " 're:',\n",
       " 'waraku',\n",
       " 'sound',\n",
       " 'good',\n",
       " 'appreci',\n",
       " 'suggest',\n",
       " 'week',\n",
       " \"we'r\",\n",
       " 'still',\n",
       " 'offlin',\n",
       " 'time',\n",
       " 'ask',\n",
       " 'refund',\n",
       " 'die',\n",
       " 'wait',\n",
       " 'magic',\n",
       " 'jack',\n",
       " 'read',\n",
       " 'youstinkatrespondingtotext',\n",
       " 'wonder',\n",
       " 'karma',\n",
       " 'point',\n",
       " 'turn',\n",
       " 'need',\n",
       " 'pack',\n",
       " 'cali',\n",
       " 'cali',\n",
       " 'not',\n",
       " 'wait',\n",
       " 'think',\n",
       " 'glass',\n",
       " 'wine',\n",
       " 'order',\n",
       " 'celebr',\n",
       " 'weekend',\n",
       " 'vaca',\n",
       " 'still',\n",
       " 'work',\n",
       " 'morrow',\n",
       " 'tho',\n",
       " 'miser',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'im',\n",
       " 'gona',\n",
       " 'cri',\n",
       " 'sux',\n",
       " 'well',\n",
       " 'ran',\n",
       " 'beer',\n",
       " 'left',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'eta',\n",
       " 'wait',\n",
       " 'wait',\n",
       " 'wait',\n",
       " 'bleh',\n",
       " 'gonna',\n",
       " 'long',\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "stemmer_snowball(new_token_list)"
   ]
  },
  {
   "source": [
    "### Vectorization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x)\n",
    "X = vectorizer.fit_transform(new_token_list)"
   ]
  },
  {
   "source": [
    "### Enregistrement de la matrice du second jeu de donn√©es"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=X)\n",
    "df.to_csv('/home/apprenant/Documents/Brief-Emotion-Analysis-Text/data/03_vectorized/text_emotion_matrix.csv', index=False)"
   ]
  }
 ]
}